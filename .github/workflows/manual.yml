# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      llm:
        # Friendly description to be shown in the UI instead of 'llm'
        description: 'LLM to evaluate'
        # Default value if no value is explicitly provided
        default: 'azure_openai'
        # Input has to be provided for the workflow to run
        required: true
        # The data type of the input
        type: string
      games:
          # Friendly description to be shown in the UI instead of 'games'
          description: 'Games to evaluate'
          # Default value if no value is explicitly provided
          default: 'games/detective.z5,games/advent.z5'
          # Input has to be provided for the workflow to run
          required: true
          # The data type of the input
          type: string
      context:
          # Friendly description to be shown in the UI instead of 'context'
          description: 'Context length'
          # Default value if no value is explicitly provided
          default: '100'
          # Input has to be provided for the workflow to run
          required: true
          # The data type of the input
          type: number
      conversation:
          # Friendly description to be shown in the UI instead of 'conversation'
          description: 'Enable conversation mode'
          # Default value if no value is explicitly provided
          default: True
          # Input has to be provided for the workflow to run
          required: true
          # The data type of the input
          type: boolean
      admissible_commands:
          # Friendly description to be shown in the UI instead of 'admissible_commands'
          description: 'Add admissible commands'
          # Default value if no value is explicitly provided
          default: True
          # Input has to be provided for the workflow to run
          required: true
          # The data type of the input
          type: boolean
      
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "evaluate"
  evaluate:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checkout the repository to the runner
      - name: Checkout repository
        uses: actions/checkout@v2
        
    # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'  # Specify the Python version you need

      # Install dependencies
      - name: Install dependencies
        run: pip install -r requirements.txt

      # Log in to Weights & Biases
      - name: Log in to Weights & Biases
        run: wandb login --host=https://microsoft-research.wandb.io
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}

      # Install plugins
      - name: Install plugins
        run: |
          llm install plugins/azure_openai
          llm install plugins/gcr_phi
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          GCR_PHI_ENDPOINT: ${{ secrets.GCR_PHI_ENDPOINT }}
          GCR_PHI_API_KEY: ${{ secrets.GCR_PHI_API_KEY }}

      # Download games
      - name: Download games
        run: python download.py
    
      # Runs a single command using the runners shell
      - name: Run evaluation
        run: |
          games_list=$(echo "${{ inputs.games }}" | tr ',' ' ')
          python benchmark.py --games $games_list --agent agent_llm.py:LLMAgent --llm ${{ inputs.llm }} --enable_wandb -vv --context ${{ inputs.context }} \
          ${{ inputs.conversation && '--conversation' || '' }} \
          ${{ inputs.admissible_commands && '--admissible_commands' || '' }}
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          GCR_PHI_ENDPOINT: ${{ secrets.GCR_PHI_ENDPOINT }}
          GCR_PHI_API_KEY: ${{ secrets.GCR_PHI_API_KEY }}
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
      
      # Upload benchmark results
      - name: Upload benchmark results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-logs
          path: tw_benchmark.log
