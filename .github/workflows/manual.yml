# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      llm:
        # Friendly description to be shown in the UI instead of 'llm'
        description: 'LLM to evaluate'
        # Default value if no value is explicitly provided
        default: 'azure_openai'
        # Input has to be provided for the workflow to run
        required: true
        # The data type of the input
        type: string
      games:
          # Friendly description to be shown in the UI instead of 'games'
          description: 'Games to evaluate'
          # Default value if no value is explicitly provided
          default: 'games/*'
          # Input has to be provided for the workflow to run
          required: true
          # The data type of the input
          type: string

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "evaluate"
  evaluate:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checkout the repository to the runner
      - name: Checkout repository
        uses: actions/checkout@v2
        
    # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'  # Specify the Python version you need

      # Install dependencies
      - name: Install dependencies
        run: pip install -r requirements.txt
    
      # Install plugins
      - name: Install plugins
        run: |
          llm install plugins/azure_openai
          llm install plugins/gcr_phi
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          GCR_PHI_ENDPOINT: ${{ secrets.GCR_PHI_ENDPOINT }}
          GCR_PHI_API_KEY: ${{ secrets.GCR_PHI_API_KEY }}

      # Download games
      - name: Download games
        run: python download.py
    
      # Runs a single command using the runners shell
      - name: Run evaluation
        run: python benchmark.py --games ${{ inputs.games }} --agent agent_llm.py:LLMAgent --llm ${{ inputs.llm }}
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          GCR_PHI_ENDPOINT: ${{ secrets.GCR_PHI_ENDPOINT }}
          GCR_PHI_API_KEY: ${{ secrets.GCR_PHI_API_KEY }}
      
      # Upload benchmark results
      - name: Upload benchmark results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-logs
          path: tw_benchmark.log
