description: Text Games Benchmark

environment:
  image: azureml/azureml_b48beba85ea5ab1bbaa48abeeab0bb21:latest
  username: modularpolicies
  registry: modularpolicies.azurecr.io
  setup:
    - pip install -r requirements.txt
    - /home/aiscuser/.local/bin/llm install plugins/gcr_llama
    - wandb login --host=https://microsoft-research.wandb.io
    - docker run --runtime nvidia --gpus all --restart unless-stopped --name vllm --env "HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}" -v ~/.cache/huggingface:/root/.cache/huggingface -p 8000:8000 --ipc=host vllm/vllm-openai:latest --model meta-llama/Meta-Llama-3.1-70B-Instruct --tensor-parallel-size 4 --host 0.0.0.0

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: $CONFIG_DIR/../

# list of jobs to run
jobs:
- name: Text Games Benchmark
  sku: G1
  identity: managed
  submit_args:
    env:
      _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/693ffe34-785e-44cd-8fb7-81da25f4d3bd/resourcegroups/ModularPolicies/providers/Microsoft.ManagedIdentity/userAssignedIdentities/modularpoliciesmi
  command:
  - python benchmark.py --agent agent_llm.py:LLMAgent --llm gcr_llama -vv --context 100 --admissible_commands
